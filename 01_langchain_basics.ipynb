{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ce9a8",
   "metadata": {},
   "source": [
    "# LangChain Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the required libraries\n",
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff28727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip - installs the packages in the base environment\n",
    "# pip - installs the packages in the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2f431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T22:20:57.186418Z",
     "start_time": "2023-09-14T22:20:56.301780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrading langchain\n",
    "pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4407a3a",
   "metadata": {},
   "source": [
    "#### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9420415",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-09-14T22:45:10.295699Z",
     "end_time": "2023-09-14T22:45:10.305068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'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'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys (OpenAI, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "os.environ.get('PINECONE_API_KEY')\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29231e2",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d355809",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... is the capital of France.', \n",
    "                   'What is the formula for the area of a circle?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0725e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an orignal tagline for a burger restaurant'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee709",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054eadaa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-14T22:45:18.620244Z",
     "end_time": "2023-09-14T22:45:18.624386Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bdecaa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-14T22:45:19.796892Z",
     "end_time": "2023-09-14T22:45:21.968999Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "761e06dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-14T22:45:24.724089Z",
     "end_time": "2023-09-14T22:45:24.734770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf mikroskopischer Ebene und erm√∂glicht es uns, ihre Eigenschaften und Interaktionen zu verstehen.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ad29b",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ed8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28accc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='HIV', language='German'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d9b84",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': 'HSV', 'language': 'french'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cc13",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68115d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9c39",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool  \n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "# agent_executor.run('Calculate the square root of the factorial of 20 \\\n",
    "# and display it with 4 decimal points')\n",
    "\n",
    "agent_executor.run('what is the answer to 5.1 ** 7.3?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
